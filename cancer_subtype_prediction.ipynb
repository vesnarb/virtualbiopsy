{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "import virtual_biopsy_utils as vbu\n",
    "import integration_images_features_utils as image_utils\n",
    "import ast\n",
    "import delong\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, brier_score_loss, precision_score, recall_score\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data paths and filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_path = '../pkls/x_train_ready_for_training.pkl'\n",
    "y_train_path = '../pkls/y_train_ready_for_training.pkl'\n",
    "\n",
    "x_val_path = '../pkls/x_val_ready_for_training.pkl'\n",
    "y_val_path = '../pkls/y_val_ready_for_training.pkl'\n",
    "\n",
    "x_test_path = '../pkls/x_test_ready_for_testing.pkl'\n",
    "y_test_path = '../pkls/y_test_ready_for_testing.pkl'\n",
    "\n",
    "shap_path = '../pkls/sentara_union_shap.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pkl.load(open(x_train_path, 'rb'))\n",
    "y_train = pkl.load(open(y_train_path, 'rb'))\n",
    "\n",
    "x_val = pkl.load(open(x_val_path, 'rb'))\n",
    "y_val = pkl.load(open(y_val_path, 'rb'))\n",
    "\n",
    "x_test = pkl.load(open(x_test_path, 'rb'))\n",
    "y_test = pkl.load(open(y_test_path, 'rb'))\n",
    "\n",
    "shap_feats = pkl.load(open(shap_path, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define grid search for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "min_child_weight = [1, 2, 3, 5, 7]  \n",
    "gamma= [0, 0.1, 0.2, 0.3, 0.4]\n",
    "colsample_bytree= [0.3, 0.4, 0.5, 0.7, 1.0]\n",
    "learning_rate= [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.50]  \n",
    "max_depth= [3, 4, 5, 6, 7, 8, 10] \n",
    "\n",
    "# Random Forest\n",
    "\n",
    "n_estimators = [50, 100, 200, 300]\n",
    "max_features = ['auto', 'sqrt']\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "tol = [1e-3, 1e-4, 1e-5]\n",
    "\n",
    "\n",
    "grid_params_xgb = {'min_child_weight': min_child_weight,\n",
    "                 'gamma': gamma,\n",
    "                 'colsample_bytree': colsample_bytree,\n",
    "                 'learning_rate': learning_rate,\n",
    "                 'max_depth': max_depth}\n",
    "\n",
    "grid_params_RF = {'clf__n_estimators': n_estimators,\n",
    "                 'clf__max_features': max_features,\n",
    "                 'clf__max_depth': max_depth,\n",
    "                 'clf__min_samples_split': min_samples_split}\n",
    "\n",
    "\n",
    "grid_params_lr = {'clf__estimator__C': C,\n",
    "                 'clf__estimator__tol': tol}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "\n",
    "classes = ['outcome_cancer_type_DCIS', 'outcome_cancer_type_Invasive', 'outcome_cancer_type_BenignHR',\n",
    "           'outcome_cancer_type_Papilloma', 'outcome_cancer_type_Benign']\n",
    "\n",
    "# annotations = [x for x in x_train if 'report' in x] + [x for x in x_train if 'calcification_in' in x] + \\\n",
    "#     [x for x in x_train if 'findings' in x] + \\\n",
    "#     ['Calcification', 'Breast Assymetry', 'Tumor', 'Architectural Distortion', 'Axillary lymphadenopathy']\n",
    "    \n",
    "predictions = [x for x in x_train if 'pred' in x]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code - TRAIN + Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(algorithm, x_train, x_val, y_train, y_val, feature_set, n_iter ):\n",
    "    \n",
    "    if algorithm == 'xgboost':\n",
    "        \n",
    "        model = XGBClassifier( eval_metric = 'auc')\n",
    "        \n",
    "        PARAM_DIST = grid_params_xgb\n",
    "        \n",
    "    elif algorithm == 'RandomForest':\n",
    "        \n",
    "        model = Pipeline([\n",
    "    ('imputation', SimpleImputer(missing_values = np.nan, strategy = 'mean')), \n",
    "    ('scaler', MinMaxScaler()), \n",
    "    ('clf', RandomForestClassifier(n_estimators = 100))\n",
    "    ])\n",
    "        PARAM_DIST = grid_params_RF\n",
    "        \n",
    "    elif algorithm == 'LogRes':\n",
    "        \n",
    "        model = Pipeline([\n",
    "    ('imputation', SimpleImputer(missing_values = np.nan, strategy = 'mean')), \n",
    "    ('scaler', MinMaxScaler()), \n",
    "    ('clf', LogisticRegression())\n",
    "    ])\n",
    "        PARAM_DIST = grid_params_lr\n",
    "        \n",
    "    model_CV= RandomizedSearchCV(estimator = model,\n",
    "                 param_distributions = PARAM_DIST,\n",
    "                 scoring = 'roc_auc', n_iter = 30, \n",
    "                 cv=5, n_jobs = -1) \n",
    "    \n",
    "    if feature_set == 'clinical':\n",
    "        \n",
    "        x_train.drop(columns=['study_id'] + predictions, inplace=True) \n",
    "        x_val.drop(columns=['study_id'] + predictions, inplace=True)\n",
    "        x_val = x_val[x_train.columns]\n",
    "        \n",
    "    elif feature_set == 'shap':\n",
    "        \n",
    "        x_train = x_train[shap_feats]\n",
    "        x_val = x_val[shap_feats]\n",
    "        x_val = x_val[x_train.columns]\n",
    "        \n",
    "#     elif feature_set == 'annotations':\n",
    "\n",
    "#         x_train = x_train [annotations]\n",
    "#         x_val = x_val [annotations]\n",
    "#         x_val = x_val[x_train.columns]\n",
    "        \n",
    "    elif feature_set == 'predictions':\n",
    "        \n",
    "        x_train = x_train [predictions]\n",
    "        x_val = x_val [predictions]\n",
    "        x_val = x_val[x_train.columns]\n",
    "    \n",
    "#     elif feature_set == 'all':\n",
    "        \n",
    "#         x_train = x_train[shap_feats + predictions + annotations] \n",
    "#         x_val = x_val[shap_feats + predictions + annotations] \n",
    "#         x_val = x_val[x_train.columns]\n",
    "    \n",
    "    elif feature_set == 'all':\n",
    "        \n",
    "        x_train = x_train[shap_feats + predictions] \n",
    "        x_val = x_val[shap_feats + predictions] \n",
    "        x_val = x_val[x_train.columns]\n",
    "        \n",
    "    stats_runs = {}\n",
    "    stats_runs['AUC_mean'] = []\n",
    "    stats_runs['AUC_CI1'] = []\n",
    "    stats_runs['AUC_CI2'] = []\n",
    "    stats_runs['probabilities'] = []\n",
    "\n",
    "\n",
    "    for i in range(n_iter):\n",
    "\n",
    "        print ('{}/{}\\r'.format(i+1, n_iter), end = '', flush=True)\n",
    "\n",
    "        for category in classes:\n",
    "\n",
    "            print('**Processing class {} ...**'.format(category))\n",
    "\n",
    "            model_CV.fit(x_train, y_train[category])\n",
    "            y_pred = model_CV.predict(x_val)\n",
    "            prob = model_CV.predict_proba(x_val)[:,1]\n",
    "\n",
    "\n",
    "            stats_runs['AUC_mean'].append(roc_auc_score(y_val[category], \n",
    "                                            prob))\n",
    "            stats_runs['AUC_CI1'].append(delong.get_delong_ci(prob, y_val[category])[0])\n",
    "            stats_runs['AUC_CI2'].append(delong.get_delong_ci(prob, y_val[category])[1])                        \n",
    "            stats_runs['probabilities'].append(prob)\n",
    "\n",
    "            pkl.dump(model_CV.best_estimator_, \n",
    "            open('../pkls/cancer_prediction_pkls/'+str(algorithm)+'/'+str(feature_set)+'/model_' + str(category) + '_run_' + str(i) + '.pkl', 'wb')) \n",
    "\n",
    "\n",
    "    # Save probabilities\n",
    "    np.savetxt('significance_tests/predict_probs_' +str(algorithm)+'_'+str(feature_set)+'.csv', stats_runs['probabilities'], delimiter=',')\n",
    "        \n",
    "    # Create output tables with AUCs in each run\n",
    "    \n",
    "    \n",
    "    outputs = {'DCIS_AUC_mean': stats_runs['AUC_mean'][0::5],\n",
    "          'DCIS_AUC_lowCI': stats_runs['AUC_CI1'][0::5],\n",
    "          'DCIS_AUC_highCI': stats_runs['AUC_CI2'][0::5]}\n",
    "    df_DCIS = pd.DataFrame(data=outputs)\n",
    "    df_DCIS.to_csv('output_AUCs_all_models/'+str(algorithm)+'_DCIS_'+str(feature_set)+'.csv')\n",
    "    \n",
    "    outputs = {'Invasive_AUC_mean': stats_runs['AUC_mean'][1::5],\n",
    "          'Invasive_AUC_lowCI': stats_runs['AUC_CI1'][1::5],\n",
    "          'Invasive_AUC_highCI': stats_runs['AUC_CI2'][1::5]}\n",
    "    df_Invasive = pd.DataFrame(data=outputs)\n",
    "    df_Invasive.to_csv('output_AUCs_all_models/'+str(algorithm)+'_Invasive_'+str(feature_set)+'.csv')\n",
    "    \n",
    "    outputs = {'BenignHR_AUC_mean': stats_runs['AUC_mean'][2::5],\n",
    "          'BenignHR_AUC_lowCI': stats_runs['AUC_CI1'][2::5],\n",
    "          'BenignHR_AUC_highCI': stats_runs['AUC_CI2'][2::5]}\n",
    "    df_BenignHR = pd.DataFrame(data=outputs)\n",
    "    df_BenignHR.to_csv('output_AUCs_all_models/'+str(algorithm)+'_BenignHR_'+str(feature_set)+'.csv')\n",
    "    \n",
    "    outputs = {'Papilloma_AUC_mean': stats_runs['AUC_mean'][3::5],\n",
    "              'Papilloma_AUC_lowCI': stats_runs['AUC_CI1'][3::5],\n",
    "              'Papilloma_AUC_highCI': stats_runs['AUC_CI2'][3::5]}\n",
    "    df_Papilloma = pd.DataFrame(data=outputs)\n",
    "    df_Papilloma.to_csv('output_AUCs_all_models/'+str(algorithm)+'_Papilloma_'+str(feature_set)+'.csv')\n",
    "    \n",
    "    outputs = {'Benign_AUC_mean': stats_runs['AUC_mean'][4::5],\n",
    "              'Benign_AUC_lowCI': stats_runs['AUC_CI1'][4::5],\n",
    "              'Benign_AUC_highCI': stats_runs['AUC_CI2'][4::5]}\n",
    "    df_Benign = pd.DataFrame(data=outputs)\n",
    "    df_Benign.to_csv('output_AUCs_all_models/'+str(algorithm)+'_Benign_'+str(feature_set)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Processing class outcome_cancer_type_DCIS ...**\n",
      "**Processing class outcome_cancer_type_Invasive ...**\n",
      "**Processing class outcome_cancer_type_BenignHR ...**\n",
      "**Processing class outcome_cancer_type_Papilloma ...**\n",
      "**Processing class outcome_cancer_type_Benign ...**\n",
      "**Processing class outcome_cancer_type_DCIS ...**\n",
      "**Processing class outcome_cancer_type_Invasive ...**\n",
      "**Processing class outcome_cancer_type_BenignHR ...**\n",
      "**Processing class outcome_cancer_type_Papilloma ...**\n",
      "**Processing class outcome_cancer_type_Benign ...**\n",
      "**Processing class outcome_cancer_type_DCIS ...**\n",
      "**Processing class outcome_cancer_type_Invasive ...**\n",
      "**Processing class outcome_cancer_type_BenignHR ...**\n",
      "**Processing class outcome_cancer_type_Papilloma ...**\n",
      "**Processing class outcome_cancer_type_Benign ...**\n",
      "**Processing class outcome_cancer_type_DCIS ...**\n",
      "**Processing class outcome_cancer_type_Invasive ...**\n",
      "**Processing class outcome_cancer_type_BenignHR ...**\n",
      "**Processing class outcome_cancer_type_Papilloma ...**\n",
      "**Processing class outcome_cancer_type_Benign ...**\n",
      "**Processing class outcome_cancer_type_DCIS ...**\n",
      "**Processing class outcome_cancer_type_Invasive ...**\n",
      "**Processing class outcome_cancer_type_BenignHR ...**\n",
      "**Processing class outcome_cancer_type_Papilloma ...**\n",
      "**Processing class outcome_cancer_type_Benign ...**\n",
      "**Processing class outcome_cancer_type_DCIS ...**\n",
      "**Processing class outcome_cancer_type_Invasive ...**\n",
      "**Processing class outcome_cancer_type_BenignHR ...**\n",
      "**Processing class outcome_cancer_type_Papilloma ...**\n",
      "**Processing class outcome_cancer_type_Benign ...**\n",
      "**Processing class outcome_cancer_type_DCIS ...**\n",
      "**Processing class outcome_cancer_type_Invasive ...**\n",
      "**Processing class outcome_cancer_type_BenignHR ...**\n",
      "**Processing class outcome_cancer_type_Papilloma ...**\n",
      "**Processing class outcome_cancer_type_Benign ...**\n",
      "**Processing class outcome_cancer_type_DCIS ...**\n",
      "**Processing class outcome_cancer_type_Invasive ...**\n",
      "**Processing class outcome_cancer_type_BenignHR ...**\n",
      "**Processing class outcome_cancer_type_Papilloma ...**\n",
      "**Processing class outcome_cancer_type_Benign ...**\n",
      "**Processing class outcome_cancer_type_DCIS ...**\n",
      "**Processing class outcome_cancer_type_Invasive ...**\n",
      "**Processing class outcome_cancer_type_BenignHR ...**\n",
      "**Processing class outcome_cancer_type_Papilloma ...**\n",
      "**Processing class outcome_cancer_type_Benign ...**\n",
      "**Processing class outcome_cancer_type_DCIS ...**\n",
      "**Processing class outcome_cancer_type_Invasive ...**\n",
      "**Processing class outcome_cancer_type_BenignHR ...**\n",
      "**Processing class outcome_cancer_type_Papilloma ...**\n",
      "**Processing class outcome_cancer_type_Benign ...**\n"
     ]
    }
   ],
   "source": [
    "train_model(algorithm = 'xgboost', x_train = x_train, \n",
    "            x_val = x_val, y_train=y_train, y_val = y_val, feature_set = 'all', n_iter = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(algorithm, x_test, y_test, feature_set, n_iter=10):\n",
    "    \n",
    "    stats_runs = {}\n",
    "    stats_runs['AUC_mean'] = []\n",
    "    stats_runs['AUC_CI1'] = []\n",
    "    stats_runs['AUC_CI2'] = []\n",
    "    stats_runs['probabilities'] = []\n",
    "\n",
    "    for category in classes:\n",
    "\n",
    "        for i in range(n_iter):\n",
    "\n",
    "            model_path = '../pkls/cancer_prediction_pkls/'+str(algorithm)+'/'+str(feature_set)+'/model_' + str(category) + '_run_' + str(i) + '.pkl'\n",
    "\n",
    "            model = pkl.load(open(model_path, 'rb'))\n",
    "\n",
    "            f = model.get_booster().feature_names\n",
    "            x_test = x_test[f]\n",
    "            y_pred = model.predict(x_test)\n",
    "            prob = model.predict_proba(x_test)[:,1]\n",
    "\n",
    "            stats_runs['AUC_mean'].append(roc_auc_score(y_test[category], \n",
    "                                            prob))\n",
    "            stats_runs['AUC_CI1'].append(delong.get_delong_ci(prob, y_test[category])[0])\n",
    "            stats_runs['AUC_CI2'].append(delong.get_delong_ci(prob, y_test[category])[1])                        \n",
    "            stats_runs['probabilities'].append(prob)\n",
    "            \n",
    "    # Save probabilities\n",
    "    np.savetxt('significance_tests/test_predict_probs_' +str(algorithm)+'_'+str(feature_set)+'.csv', stats_runs['probabilities'], delimiter=',')\n",
    "\n",
    "        # Create output tables with AUCs in each run\n",
    "\n",
    "    outputs = {'DCIS_AUC_mean': stats_runs['AUC_mean'][:10],\n",
    "              'DCIS_AUC_lowCI': stats_runs['AUC_CI1'][:10],\n",
    "              'DCIS_AUC_highCI': stats_runs['AUC_CI2'][:10]}\n",
    "    df_DCIS = pd.DataFrame(data=outputs)\n",
    "    df_DCIS.to_csv('output_AUCs_all_models/test_'+str(algorithm)+'_DCIS_'+str(feature_set)+'.csv')\n",
    "\n",
    "    outputs = {'Invasive_AUC_mean': stats_runs['AUC_mean'][10:20],\n",
    "              'Invasive_AUC_lowCI': stats_runs['AUC_CI1'][10:20],\n",
    "              'Invasive_AUC_highCI': stats_runs['AUC_CI2'][10:20]}\n",
    "    df_Invasive = pd.DataFrame(data=outputs)\n",
    "    df_Invasive.to_csv('output_AUCs_all_models/test_'+str(algorithm)+'_Invasive_'+str(feature_set)+'.csv')\n",
    "\n",
    "    outputs = {'BenignHR_AUC_mean': stats_runs['AUC_mean'][20:30],\n",
    "              'BenignHR_AUC_lowCI': stats_runs['AUC_CI1'][20:30],\n",
    "              'BenignHR_AUC_highCI': stats_runs['AUC_CI2'][20:30]}\n",
    "    df_BenignHR = pd.DataFrame(data=outputs)\n",
    "    df_BenignHR.to_csv('output_AUCs_all_models/test_'+str(algorithm)+'_BenignHR_'+str(feature_set)+'.csv')\n",
    "\n",
    "    outputs = {'Papilloma_AUC_mean': stats_runs['AUC_mean'][30:40],\n",
    "                  'Papilloma_AUC_lowCI': stats_runs['AUC_CI1'][30:40],\n",
    "                  'Papilloma_AUC_highCI': stats_runs['AUC_CI2'][30:40]}\n",
    "    df_Papilloma = pd.DataFrame(data=outputs)\n",
    "    df_Papilloma.to_csv('output_AUCs_all_models/test_'+str(algorithm)+'_Papilloma_'+str(feature_set)+'.csv')\n",
    "\n",
    "    outputs = {'Benign_AUC_mean': stats_runs['AUC_mean'][40:50],\n",
    "                  'Benign_AUC_lowCI': stats_runs['AUC_CI1'][40:50],\n",
    "                  'Benign_AUC_highCI': stats_runs['AUC_CI2'][40:50]}\n",
    "    df_Benign = pd.DataFrame(data=outputs)\n",
    "    df_Benign.to_csv('output_AUCs_all_models/test_'+str(algorithm)+'_Benign_'+str(feature_set)+'.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model('xgboost', x_test, y_test, feature_set = 'shap', n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model('xgboost', x_test, y_test, feature_set = 'predictions', n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model('xgboost', x_test, y_test, feature_set = 'all', n_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boostrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_subsampling_weights(df, outcome_freq):\n",
    "    '''Adds a weights colum to the df according to given frequencies'''\n",
    "    \n",
    "    # DCIS\n",
    "    inds_dcis = df['outcome_cancer_type_DCIS'] == 1\n",
    "    \n",
    "    # Inv\n",
    "    inds_inv = df['outcome_cancer_type_Invasive'] == 1\n",
    "    \n",
    "    # BenHR\n",
    "    inds_benhr = df['outcome_cancer_type_BenignHR'] == 1\n",
    "\n",
    "    # PAp\n",
    "    inds_pap = df['outcome_cancer_type_Papilloma'] == 1\n",
    "\n",
    "    # Benign\n",
    "    inds_ben = df['outcome_cancer_type_Benign'] == 1\n",
    "    \n",
    "    \n",
    "    outcome_num_all = [sum(inds_dcis), sum(inds_inv), sum(inds_benhr), sum(inds_pap), sum(inds_ben)]\n",
    "    \n",
    "    weights = [outcome_freq[i]/outcome_num_all[i] for i in range(len(outcome_num_all))]\n",
    "    \n",
    "    df.loc[inds_dcis, 'outcome_weights'] = weights[0]\n",
    "    df.loc[inds_inv, 'outcome_weights'] = weights[1]\n",
    "    df.loc[inds_benhr, 'outcome_weights'] = weights[2]\n",
    "    df.loc[inds_pap, 'outcome_weights'] = weights[3]\n",
    "    df.loc[inds_ben, 'outcome_weights'] = weights[4]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ensemble_model_bootstrap(algorithm, y_test, bootstrap_rep =10000, sample_size = y_test.shape[0]):\n",
    "    \n",
    "    stats_runs = {}\n",
    "    stats_runs['AUC_DCIS_img'] = []\n",
    "    stats_runs['AUC_DCIS_CI1_img'] = []\n",
    "    stats_runs['AUC_DCIS_CI2_img'] = []\n",
    "    \n",
    "    stats_runs['AUC_INV_img'] = []\n",
    "    stats_runs['AUC_INV_CI1_img'] = []\n",
    "    stats_runs['AUC_INV_CI2_img'] = []\n",
    "    \n",
    "    stats_runs['AUC_BENHR_img'] = []\n",
    "    stats_runs['AUC_BENHR_CI1_img'] = []\n",
    "    stats_runs['AUC_BENHR_CI2_img'] = []\n",
    "    \n",
    "    stats_runs['AUC_PAP_img'] = []\n",
    "    stats_runs['AUC_PAP_CI1_img'] = []\n",
    "    stats_runs['AUC_PAP_CI2_img'] = []\n",
    "    \n",
    "    stats_runs['AUC_BEN_img'] = []\n",
    "    stats_runs['AUC_BEN_CI1_img'] = []\n",
    "    stats_runs['AUC_BEN_CI2_img'] = []\n",
    "\n",
    " \n",
    "\n",
    "    stats_runs['AUC_DCIS_both'] = []\n",
    "    stats_runs['AUC_DCIS_CI1_both'] = []\n",
    "    stats_runs['AUC_DCIS_CI2_both'] = []\n",
    "    \n",
    "    stats_runs['AUC_INV_both'] = []\n",
    "    stats_runs['AUC_INV_CI1_both'] = []\n",
    "    stats_runs['AUC_INV_CI2_both'] = []\n",
    "    \n",
    "    stats_runs['AUC_BENHR_both'] = []\n",
    "    stats_runs['AUC_BENHR_CI1_both'] = []\n",
    "    stats_runs['AUC_BENHR_CI2_both'] = []\n",
    "    \n",
    "    stats_runs['AUC_PAP_both'] = []\n",
    "    stats_runs['AUC_PAP_CI1_both'] = []\n",
    "    stats_runs['AUC_PAP_CI2_both'] = []\n",
    "    \n",
    "    stats_runs['AUC_BEN_both'] = []\n",
    "    stats_runs['AUC_BEN_CI1_both'] = []\n",
    "    stats_runs['AUC_BEN_CI2_both'] = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Take enseble of the 10 test runs (load predicted probabilities of all 10 runs on test and take average)\n",
    "\n",
    "    # these files contain predictions for all classes (each 10 rows is one class)\n",
    "\n",
    "    path_prob_img = 'significance_tests/test_predict_probs_xgboost_predictions.csv'\n",
    "    path_prob_both = 'significance_tests/test_predict_probs_xgboost_all.csv'\n",
    "    \n",
    "#     prob_shap = pd.read_csv(path_prob_shap, header = None)\n",
    "    prob_img = pd.read_csv(path_prob_img, header = None)\n",
    "    prob_both = pd.read_csv(path_prob_both, header = None)\n",
    "     \n",
    "    # All features\n",
    "    \n",
    "    avg_predictions_dcis_all = prob_both[:10].mean()\n",
    "    avg_predictions_inv_all = prob_both[10:20].mean()\n",
    "    avg_predictions_benhr_all = prob_both[20:30].mean()\n",
    "    avg_predictions_pap_all = prob_both[30:40].mean()\n",
    "    avg_predictions_ben_all = prob_both[40:50].mean()\n",
    "    \n",
    "\n",
    "    # imaging\n",
    "    \n",
    "    avg_predictions_dcis_img = prob_img[:10].mean()\n",
    "    avg_predictions_inv_img = prob_img[10:20].mean()\n",
    "    avg_predictions_benhr_img = prob_img[20:30].mean()\n",
    "    avg_predictions_pap_img = prob_img[30:40].mean()\n",
    "    avg_predictions_ben_img = prob_img[40:50].mean()\n",
    "    \n",
    "    OUTCOME_FREQ = [11.33, 24.36, 2.83, 4.82, 58.07] # frequencies dcis, inv, benhr, pap, ben\n",
    "        \n",
    "    y_test_with_weights = add_subsampling_weights(y_test, OUTCOME_FREQ)\n",
    "    norm_weights = y_test['outcome_weights']/np.sum(y_test['outcome_weights'])\n",
    "\n",
    "            \n",
    "    for i in range(bootstrap_rep):\n",
    "                                \n",
    "        print ('{}/{}\\r'.format(i+1, bootstrap_rep), end = '', flush=True)\n",
    "                \n",
    "        samp_inds = np.random.choice(y_test.shape[0], sample_size, replace=True, p=norm_weights)\n",
    "                        \n",
    "        y_test_sample_dcis = y_test.iloc[samp_inds]['outcome_cancer_type_DCIS'].to_numpy()\n",
    "        y_test_sample_inv = y_test.iloc[samp_inds]['outcome_cancer_type_Invasive'].to_numpy()\n",
    "        y_test_sample_benhr = y_test.iloc[samp_inds]['outcome_cancer_type_BenignHR'].to_numpy()\n",
    "        y_test_sample_pap = y_test.iloc[samp_inds]['outcome_cancer_type_Papilloma'].to_numpy()\n",
    "        y_test_sample_ben = y_test.iloc[samp_inds]['outcome_cancer_type_Benign'].to_numpy()\n",
    "        \n",
    "#         print(y_test_sample_dcis.sum()/len(samp_inds)*100)\n",
    "#         print(y_test_sample_inv.sum()/len(samp_inds)*100)\n",
    "#         print(y_test_sample_benhr.sum()/len(samp_inds)*100)\n",
    "#         print(y_test_sample_pap.sum()/len(samp_inds)*100)\n",
    "#         print(y_test_sample_ben.sum()/len(samp_inds)*100)\n",
    "        \n",
    "#         print('\\n')\n",
    "        \n",
    "        # imaging sample probabilities\n",
    "        predicted_probs_img_dcis_sample = avg_predictions_dcis_img[samp_inds].to_numpy()\n",
    "        predicted_probs_img_inv_sample = avg_predictions_inv_img[samp_inds].to_numpy()\n",
    "        predicted_probs_img_benhr_sample = avg_predictions_benhr_img[samp_inds].to_numpy()\n",
    "        predicted_probs_img_pap_sample = avg_predictions_pap_img[samp_inds].to_numpy()\n",
    "        predicted_probs_img_ben_sample = avg_predictions_ben_img[samp_inds].to_numpy()\n",
    "        \n",
    "        # both features sample probabilities\n",
    "        predicted_probs_all_dcis_sample = avg_predictions_dcis_all[samp_inds].to_numpy()\n",
    "        predicted_probs_all_inv_sample = avg_predictions_inv_all[samp_inds].to_numpy()\n",
    "        predicted_probs_all_benhr_sample = avg_predictions_benhr_all[samp_inds].to_numpy()\n",
    "        predicted_probs_all_pap_sample = avg_predictions_pap_all[samp_inds].to_numpy()\n",
    "        predicted_probs_all_ben_sample = avg_predictions_ben_all[samp_inds].to_numpy()        \n",
    "        \n",
    "\n",
    "        # AUCs images\n",
    "        stats_runs['AUC_DCIS_img'].append(roc_auc_score(y_test_sample_dcis, \n",
    "                                                predicted_probs_img_dcis_sample))\n",
    "        stats_runs['AUC_DCIS_CI1_img'].append(delong.get_delong_ci(predicted_probs_img_dcis_sample, y_test_sample_dcis)[0])\n",
    "        stats_runs['AUC_DCIS_CI2_img'].append(delong.get_delong_ci(predicted_probs_img_dcis_sample, y_test_sample_dcis)[1]) \n",
    " \n",
    "        stats_runs['AUC_INV_img'].append(roc_auc_score(y_test_sample_inv, \n",
    "                                                predicted_probs_img_inv_sample))\n",
    "        stats_runs['AUC_INV_CI1_img'].append(delong.get_delong_ci(predicted_probs_img_inv_sample, y_test_sample_inv)[0])\n",
    "        stats_runs['AUC_INV_CI2_img'].append(delong.get_delong_ci(predicted_probs_img_inv_sample, y_test_sample_inv)[1])\n",
    "\n",
    "        stats_runs['AUC_BENHR_img'].append(roc_auc_score(y_test_sample_benhr, \n",
    "                                                predicted_probs_img_benhr_sample))\n",
    "        stats_runs['AUC_BENHR_CI1_img'].append(delong.get_delong_ci(predicted_probs_img_benhr_sample, y_test_sample_benhr)[0])\n",
    "        stats_runs['AUC_BENHR_CI2_img'].append(delong.get_delong_ci(predicted_probs_img_benhr_sample, y_test_sample_benhr)[1])\n",
    "        \n",
    "        stats_runs['AUC_PAP_img'].append(roc_auc_score(y_test_sample_pap, \n",
    "                                                predicted_probs_img_pap_sample))\n",
    "        stats_runs['AUC_PAP_CI1_img'].append(delong.get_delong_ci(predicted_probs_img_pap_sample, y_test_sample_pap)[0])\n",
    "        stats_runs['AUC_PAP_CI2_img'].append(delong.get_delong_ci(predicted_probs_img_pap_sample, y_test_sample_pap)[1])\n",
    "        \n",
    "        stats_runs['AUC_BEN_img'].append(roc_auc_score(y_test_sample_ben, \n",
    "                                                predicted_probs_img_ben_sample))\n",
    "        stats_runs['AUC_BEN_CI1_img'].append(delong.get_delong_ci(predicted_probs_img_ben_sample, y_test_sample_ben)[0])\n",
    "        stats_runs['AUC_BEN_CI2_img'].append(delong.get_delong_ci(predicted_probs_img_ben_sample, y_test_sample_ben)[1])\n",
    "    \n",
    "\n",
    "        # Performance Both\n",
    "        stats_runs['AUC_DCIS_both'].append(roc_auc_score(y_test_sample_dcis, \n",
    "                                                predicted_probs_all_dcis_sample))\n",
    "        stats_runs['AUC_DCIS_CI1_both'].append(delong.get_delong_ci(predicted_probs_all_dcis_sample, y_test_sample_dcis)[0])\n",
    "        stats_runs['AUC_DCIS_CI2_both'].append(delong.get_delong_ci(predicted_probs_all_dcis_sample, y_test_sample_dcis)[1]) \n",
    " \n",
    "        stats_runs['AUC_INV_both'].append(roc_auc_score(y_test_sample_inv, \n",
    "                                                predicted_probs_all_inv_sample))\n",
    "        stats_runs['AUC_INV_CI1_both'].append(delong.get_delong_ci(predicted_probs_all_inv_sample, y_test_sample_inv)[0])\n",
    "        stats_runs['AUC_INV_CI2_both'].append(delong.get_delong_ci(predicted_probs_all_inv_sample, y_test_sample_inv)[1])\n",
    "\n",
    "        stats_runs['AUC_BENHR_both'].append(roc_auc_score(y_test_sample_benhr, \n",
    "                                                predicted_probs_all_benhr_sample))\n",
    "        stats_runs['AUC_BENHR_CI1_both'].append(delong.get_delong_ci(predicted_probs_all_benhr_sample, y_test_sample_benhr)[0])\n",
    "        stats_runs['AUC_BENHR_CI2_both'].append(delong.get_delong_ci(predicted_probs_all_benhr_sample, y_test_sample_benhr)[1])\n",
    "        \n",
    "        stats_runs['AUC_PAP_both'].append(roc_auc_score(y_test_sample_pap, \n",
    "                                                predicted_probs_all_pap_sample))\n",
    "        stats_runs['AUC_PAP_CI1_both'].append(delong.get_delong_ci(predicted_probs_all_pap_sample, y_test_sample_pap)[0])\n",
    "        stats_runs['AUC_PAP_CI2_both'].append(delong.get_delong_ci(predicted_probs_all_pap_sample, y_test_sample_pap)[1])\n",
    "        \n",
    "        stats_runs['AUC_BEN_both'].append(roc_auc_score(y_test_sample_ben, \n",
    "                                                predicted_probs_all_ben_sample))\n",
    "        stats_runs['AUC_BEN_CI1_both'].append(delong.get_delong_ci(predicted_probs_all_ben_sample, y_test_sample_ben)[0])\n",
    "        stats_runs['AUC_BEN_CI2_both'].append(delong.get_delong_ci(predicted_probs_all_ben_sample, y_test_sample_ben)[1])\n",
    "    \n",
    "\n",
    "       \n",
    "\n",
    "        # Create output tables with AUCs in each run\n",
    "\n",
    "        outputs = {'AUC_DCIS_img': stats_runs['AUC_DCIS_img'],\n",
    "              'AUC_DCIS_CI1_img': stats_runs['AUC_DCIS_CI1_img'],\n",
    "              'AUC_DCIS_CI2_img': stats_runs['AUC_DCIS_CI2_img'],\n",
    "                  \n",
    "                  'AUC_INV_img': stats_runs['AUC_INV_img'],\n",
    "              'AUC_INV_CI1_img': stats_runs['AUC_INV_CI1_img'],\n",
    "              'AUC_INV_CI2_img': stats_runs['AUC_INV_CI2_img'],\n",
    "\n",
    "                  'AUC_BENHR_img': stats_runs['AUC_BENHR_img'],\n",
    "              'AUC_BENHR_img': stats_runs['AUC_BENHR_CI1_img'],\n",
    "              'AUC_BENHR_img': stats_runs['AUC_BENHR_CI2_img'],  \n",
    "                  \n",
    "                  'AUC_PAP_img': stats_runs['AUC_PAP_img'],\n",
    "              'AUC_PAP_img': stats_runs['AUC_PAP_CI1_img'],\n",
    "              'AUC_PAP_img': stats_runs['AUC_PAP_CI2_img'],\n",
    "                  \n",
    "                  'AUC_BEN_img': stats_runs['AUC_BEN_img'],\n",
    "              'AUC_BEN_img': stats_runs['AUC_BEN_CI1_img'],\n",
    "              'AUC_BEN_img': stats_runs['AUC_BEN_CI2_img'],                \n",
    "                  \n",
    "                \n",
    "                   \n",
    "                  'AUC_DCIS_both': stats_runs['AUC_DCIS_both'],\n",
    "              'AUC_DCIS_CI1_both': stats_runs['AUC_DCIS_CI1_both'],\n",
    "              'AUC_DCIS_CI2_both': stats_runs['AUC_DCIS_CI2_both'],\n",
    "                  \n",
    "                  'AUC_INV_both': stats_runs['AUC_INV_both'],\n",
    "              'AUC_INV_CI1_both': stats_runs['AUC_INV_CI1_both'],\n",
    "              'AUC_INV_CI2_both': stats_runs['AUC_INV_CI2_both'],\n",
    "\n",
    "                  'AUC_BENHR_both': stats_runs['AUC_BENHR_both'],\n",
    "              'AUC_BENHR_both': stats_runs['AUC_BENHR_CI1_both'],\n",
    "              'AUC_BENHR_both': stats_runs['AUC_BENHR_CI2_both'],  \n",
    "                  \n",
    "                  'AUC_PAP_both': stats_runs['AUC_PAP_both'],\n",
    "              'AUC_PAP_both': stats_runs['AUC_PAP_CI1_both'],\n",
    "              'AUC_PAP_both': stats_runs['AUC_PAP_CI2_both'],\n",
    "                  \n",
    "                  'AUC_BEN_both': stats_runs['AUC_BEN_both'],\n",
    "              'AUC_BEN_both': stats_runs['AUC_BEN_CI1_both'],\n",
    "              'AUC_BEN_both': stats_runs['AUC_BEN_CI2_both'], \n",
    "                  \n",
    "     \n",
    "                  \n",
    "                  }\n",
    "        df = pd.DataFrame(data=outputs)\n",
    "\n",
    "#         df.to_csv('output_AUCs_all_models/test_boostrap_ensemble_Multiclass.csv')\n",
    "        df.to_csv('output_AUCs_all_models/test_boostrap_ensemble_Multiclass_sample_size_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822/10000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degrees of freedom <= 0 for slice\n",
      "divide by zero encountered in true_divide\n",
      "invalid value encountered in multiply\n",
      "Degrees of freedom <= 0 for slice\n",
      "divide by zero encountered in true_divide\n",
      "invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2103/10000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degrees of freedom <= 0 for slice\n",
      "divide by zero encountered in true_divide\n",
      "invalid value encountered in multiply\n",
      "Degrees of freedom <= 0 for slice\n",
      "divide by zero encountered in true_divide\n",
      "invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4434/10000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degrees of freedom <= 0 for slice\n",
      "divide by zero encountered in true_divide\n",
      "invalid value encountered in multiply\n",
      "Degrees of freedom <= 0 for slice\n",
      "divide by zero encountered in true_divide\n",
      "invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6433/10000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degrees of freedom <= 0 for slice\n",
      "divide by zero encountered in true_divide\n",
      "invalid value encountered in multiply\n",
      "Degrees of freedom <= 0 for slice\n",
      "divide by zero encountered in true_divide\n",
      "invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6980/10000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degrees of freedom <= 0 for slice\n",
      "divide by zero encountered in true_divide\n",
      "invalid value encountered in multiply\n",
      "Degrees of freedom <= 0 for slice\n",
      "divide by zero encountered in true_divide\n",
      "invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9662/10000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degrees of freedom <= 0 for slice\n",
      "divide by zero encountered in true_divide\n",
      "invalid value encountered in multiply\n",
      "Degrees of freedom <= 0 for slice\n",
      "divide by zero encountered in true_divide\n",
      "invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000\r"
     ]
    }
   ],
   "source": [
    "test_ensemble_model_bootstrap('xgboost', y_test.reset_index(drop=True), bootstrap_rep =10000, sample_size = y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000\r"
     ]
    }
   ],
   "source": [
    "test_ensemble_model_bootstrap('xgboost', y_test.reset_index(drop=True), \n",
    "                              bootstrap_rep =10000, sample_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
