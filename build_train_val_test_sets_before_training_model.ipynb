{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "import virtual_biopsy_utils as vbu\n",
    "import integration_images_features_utils as image_utils\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sentara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2395, 7714)\n"
     ]
    }
   ],
   "source": [
    "sen_data = vbu.load_sentara(path = '../pkls/sentara.pkl', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = pd.read_csv('../input_files/tal_predictions_heldout.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_csv('../input_files/tal_predictions_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('../input_files/tal_predictions_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "viewpoint\n",
       "MLO     2552\n",
       "CC      2399\n",
       "ML         4\n",
       "SCC        2\n",
       "MCC        1\n",
       "MML        1\n",
       "SMLO       1\n",
       "XCCL       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [t, v, h]\n",
    "data = pd.concat(frames)\n",
    "data = data[data['provider'] == 'sentara']\n",
    "data = data[data['viewpoint'] != 'LMO']\n",
    "data = data[data['viewpoint'] != 'MLOIMF']\n",
    "data.groupby('viewpoint').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input_files/final_tal_predictons_without_annotation_all.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/19/h8t2gt5548q4mx44r1w44vjh0000gn/T/ipykernel_81787/3324367082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input_files/final_tal_predictons_without_annotation_all.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input_files/sentara_train_studies.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input_files/sentara_val_studies.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/virtualbiopsy/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/virtualbiopsy/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/virtualbiopsy/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/virtualbiopsy/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/virtualbiopsy/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/virtualbiopsy/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/virtualbiopsy/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/virtualbiopsy/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input_files/final_tal_predictons_without_annotation_all.csv'"
     ]
    }
   ],
   "source": [
    "pred_file_path = '../input_files/final_tal_predictons_without_annotation_all.csv'\n",
    "pred= pd.read_csv(pred_file_path)\n",
    "\n",
    "train = [x.split('\\t') for x in open('../input_files/sentara_train_studies.txt').readlines()]\n",
    "val = [x.split('\\t') for x in open('../input_files/sentara_val_studies.txt').readlines()]\n",
    "test = [x.split('\\t') for x in open('../input_files/sentara_test_studies.txt').readlines()]\n",
    "\n",
    "studies_train = [item[1] for item in train[1:]]\n",
    "studies_val = [item[1] for item in val[1:]]\n",
    "studies_test = [item[1] for item in test[1:]]\n",
    "\n",
    "pats_train = [item[0] for item in train[1:]]\n",
    "pats_val = [item[0] for item in val[1:]]\n",
    "pats_test = [item[0] for item in test[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = pred.image_id.unique()\n",
    "\n",
    "lesions_per_image = []\n",
    "for i in images:\n",
    "    lesions_per_image.append(pred[pred['image_id'] == i].finding_id.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(lesions_per_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5819, 33)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5819"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(pred.xml_url.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(pats_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(studies_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(x_test.index.get_level_values('patient_id').tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of images\n",
    "pred[pred['study_id'].isin(studies_val)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(pred[pred['study_id'].isin(studies_val)].xml_url.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imperst = []\n",
    "for p in list(studies_train) + list(studies_val)+list(studies_test):\n",
    "    imperst.append(pred[pred['study_id'] == p].shape[0])\n",
    "set(imperst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2336"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(sen_data.index.get_level_values('patient_id').tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pats = list(set(sen_data.index.get_level_values('patient_id').tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>outcome_biopsy_result_1yr</th>\n",
       "      <th>outcome_bc_1yr</th>\n",
       "      <th>outcome_bc_2yr</th>\n",
       "      <th>outcome_calc_max_birads</th>\n",
       "      <th>outcome_birads_1yr</th>\n",
       "      <th>prev_biopsy_result_max</th>\n",
       "      <th>prev_birads_ind</th>\n",
       "      <th>breast_MRI_cnt</th>\n",
       "      <th>breast_MRI_ind</th>\n",
       "      <th>...</th>\n",
       "      <th>bmi_variance</th>\n",
       "      <th>bmi_change</th>\n",
       "      <th>months_since_first_MG</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>outcome_cancer_type_DCIS</th>\n",
       "      <th>outcome_cancer_type_Invasive</th>\n",
       "      <th>outcome_cancer_type_BenignHR</th>\n",
       "      <th>outcome_cancer_type_Papilloma</th>\n",
       "      <th>outcome_cancer_type_Benign</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <th>50700289</th>\n",
       "      <th>2013-08-22</th>\n",
       "      <td>MG130822004599</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 7713 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  study_id  outcome_biopsy_result_1yr  \\\n",
       "     patient_id study_date                                              \n",
       "1490 50700289   2013-08-22  MG130822004599                        2.0   \n",
       "\n",
       "                            outcome_bc_1yr  outcome_bc_2yr  \\\n",
       "     patient_id study_date                                   \n",
       "1490 50700289   2013-08-22             0.0             0.0   \n",
       "\n",
       "                            outcome_calc_max_birads  outcome_birads_1yr  \\\n",
       "     patient_id study_date                                                \n",
       "1490 50700289   2013-08-22                      0.0                 4.0   \n",
       "\n",
       "                            prev_biopsy_result_max  prev_birads_ind  \\\n",
       "     patient_id study_date                                            \n",
       "1490 50700289   2013-08-22                     0.0              1.0   \n",
       "\n",
       "                            breast_MRI_cnt  breast_MRI_ind  ...  bmi_variance  \\\n",
       "     patient_id study_date                                  ...                 \n",
       "1490 50700289   2013-08-22             0.0             0.0  ...           NaN   \n",
       "\n",
       "                            bmi_change  months_since_first_MG  race  religion  \\\n",
       "     patient_id study_date                                                      \n",
       "1490 50700289   2013-08-22         NaN                    NaN   1.0       1.0   \n",
       "\n",
       "                            outcome_cancer_type_DCIS  \\\n",
       "     patient_id study_date                             \n",
       "1490 50700289   2013-08-22                         0   \n",
       "\n",
       "                            outcome_cancer_type_Invasive  \\\n",
       "     patient_id study_date                                 \n",
       "1490 50700289   2013-08-22                             0   \n",
       "\n",
       "                            outcome_cancer_type_BenignHR  \\\n",
       "     patient_id study_date                                 \n",
       "1490 50700289   2013-08-22                             0   \n",
       "\n",
       "                            outcome_cancer_type_Papilloma  \\\n",
       "     patient_id study_date                                  \n",
       "1490 50700289   2013-08-22                              1   \n",
       "\n",
       "                            outcome_cancer_type_Benign  \n",
       "     patient_id study_date                              \n",
       "1490 50700289   2013-08-22                           0  \n",
       "\n",
       "[1 rows x 7713 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_data[np.in1d(sen_data.index.get_level_values(1), pats[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_studies = []\n",
    "for p in pats:\n",
    "    n_studies.append(sen_data[np.in1d(sen_data.index.get_level_values(1), p)].shape[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(n_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-11-01 00:00:00')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(set(sen_data.index.get_level_values('study_date').tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load shared features between maccabi and sentara "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_path = '../pkls/x_train_ready_for_training.pkl'\n",
    "x_train_after = pkl.load(open(x_train_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1842"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared = pkl.load(open('../pkls/shared_features_mac_sen.pkl', 'rb'))\n",
    "\n",
    "len(shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add calculated features to sentara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add BMI estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen_data = vbu.add_bmi_estimation_sentara(df=sen_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add likelihood of obesity estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen_data = vbu.add_likelihood_obesity_estimation_sentara(df=sen_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Breast density estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen_data = vbu.add_density_estimation_sentara(df = sen_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use shared  features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen_data = sen_data[shared]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train: 1685, val: 357 and test: 353\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = vbu.split_sentara(sen_data, \n",
    "                                train_path = '../pkls/sentara_train.pkl',\n",
    "                                val_path = '../pkls/sentara_val.pkl', \n",
    "                                test_path = '../pkls/sentara_test.pkl', overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform multilabel to single label - only on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen_data_train = x_train.combine_first(y_train)\n",
    "\n",
    "cancers = [x for x in sen_data_train if 'outcome_cancer_type' in x]\n",
    "\n",
    "temp = []\n",
    "for _, row in sen_data_train.iterrows():\n",
    "    \n",
    "    cols_one = row[cancers].loc[lambda x:x==True].index\n",
    "    for col_name in cols_one:\n",
    "        temp_row = row.copy()\n",
    "        temp_row[cancers] = 0\n",
    "        temp_row[col_name] = 1\n",
    "        temp.append(temp_row)\n",
    "        \n",
    "sen_data_train = pd.DataFrame(temp)\n",
    "multiindex = sen_data_train.index.tolist()\n",
    "sen_data_train.reset_index(inplace=True)\n",
    "sen_data_train['patient_id'] = [item[1] for item in multiindex]\n",
    "sen_data_train['study_date'] = [item[2] for item in multiindex]\n",
    "sen_data_train.set_index(['patient_id', 'study_date'], inplace = True, append=True)\n",
    "sen_data_train.drop('index', axis = 1, inplace=True)\n",
    "print('New number of samples of training set: %d' %sen_data_train.shape[0])\n",
    "\n",
    "# Redefine new training dataframes with the single label samples\n",
    "y_train = sen_data_train[[x for x in sen_data_train.columns if x.startswith('outcome_cancer_')]]\n",
    "x_train = sen_data_train.drop(columns=[x for x in sen_data_train.columns if x.startswith('outcome_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add imaging features to all sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file from image classifier with entire set (train, test, val)\n",
    "pred_file_path = '../input_files/final_tal_predictons_without_annotation_all.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = image_utils.compute_predictions_images_sentara(pred_file_path)\n",
    "\n",
    "x_train = x_train.join(pred.set_index('study_id'), on='study_id')\n",
    "x_val = x_val.join(pred.set_index('study_id'), on='study_id')\n",
    "x_test = x_test.join(pred.set_index('study_id'), on='study_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Findings size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finding_size = image_utils.compute_findings_size(pred_file_path)\n",
    "\n",
    "# x_train = x_train.join(finding_size.set_index('study_id'), on='study_id')\n",
    "# x_val = x_val.join(finding_size.set_index('study_id'), on='study_id')\n",
    "# x_test = x_test.join(finding_size.set_index('study_id'), on='study_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Types: Calcification, breast assymetry, tumor, architectural distortion, axillary lymphadenopa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# types = image_utils.get_types(pred_file_path)\n",
    "\n",
    "# x_train = x_train.join(types.set_index('study_id'), on='study_id')\n",
    "# x_val = x_val.join(types.set_index('study_id'), on='study_id')\n",
    "# x_test = x_test.join(types.set_index('study_id'), on='study_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Microcalcifications and Macrocalcifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# micro = image_utils.get_micro_and_macro(pred_file_path)\n",
    "\n",
    "# x_train = x_train.join(micro.set_index('study_id'), on='study_id')\n",
    "# x_val = x_val.join(micro.set_index('study_id'), on='study_id')\n",
    "# x_test = x_test.join(micro.set_index('study_id'), on='study_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ella's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spic_lesions_studies = [x.split('\\t') for x in open('../input_files/additional_features_spiculated_lesions_sentara.txt').readlines()]\n",
    "# arch_dist_studies = [x.split('\\t') for x in open('../input_files/additional_features_architectural_distortion_sentara.txt').readlines()]\n",
    "# susp_calc_studies = [x.split('\\t') for x in open('../input_files/additional_features_suspicius_calcifications_sentara.txt').readlines()]\n",
    "\n",
    "# spic_lesions_studies = [item[1][:-1] for item in spic_lesions_studies[1:]]\n",
    "# arch_dist_studies = [item[1][:-1] for item in arch_dist_studies[1:]]\n",
    "# susp_calc_studies = [item[1][:-1] for item in susp_calc_studies[1:]]\n",
    "\n",
    "# x_train['spiculated_lesions_report'] = np.array([x in spic_lesions_studies for x in x_train.study_id.tolist()]).astype(int)\n",
    "# x_train['architectural_distortion_report'] = np.array([x in arch_dist_studies for x in x_train.study_id.tolist()]).astype(int)\n",
    "# x_train['suspicious_calcifications_report'] = np.array([x in susp_calc_studies for x in x_train.study_id.tolist()]).astype(int)\n",
    "\n",
    "# x_val['spiculated_lesions_report'] = np.array([x in spic_lesions_studies for x in x_val.study_id.tolist()]).astype(int)\n",
    "# x_val['architectural_distortion_report'] = np.array([x in arch_dist_studies for x in x_val.study_id.tolist()]).astype(int)\n",
    "# x_val['suspicious_calcifications_report'] = np.array([x in susp_calc_studies for x in x_val.study_id.tolist()]).astype(int)\n",
    "\n",
    "\n",
    "# x_test['spiculated_lesions_report'] = np.array([x in spic_lesions_studies for x in x_test.study_id.tolist()]).astype(int)\n",
    "# x_test['architectural_distortion_report'] = np.array([x in arch_dist_studies for x in x_test.study_id.tolist()]).astype(int)\n",
    "# x_test['suspicious_calcifications_report'] = np.array([x in susp_calc_studies for x in x_test.study_id.tolist()]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../pkls/x_test_ready_for_testing.pkl', 'wb') as handle:\n",
    "    pkl.dump(x_test, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('../pkls/y_test_ready_for_testing.pkl', 'wb') as handle:\n",
    "    pkl.dump(y_test, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../pkls/x_train_ready_for_training.pkl', 'wb') as handle:\n",
    "    pkl.dump(x_train, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../pkls/y_train_ready_for_training.pkl', 'wb') as handle:\n",
    "    pkl.dump(y_train, handle, protocol=pkl.HIGHEST_PROTOCOL)   \n",
    "    \n",
    "with open('../pkls/x_val_ready_for_training.pkl', 'wb') as handle:\n",
    "    pkl.dump(x_val, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../pkls/y_val_ready_for_training.pkl', 'wb') as handle:\n",
    "    pkl.dump(y_val, handle, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
